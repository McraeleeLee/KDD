## key point:

### 解题关键
  "该赛道的数据集强调电商推荐系统的公平性，尤其是流量较少的广大中小商家所面临的“有好货却无人问津”的困境。数据横跨十余天，中间还穿插了某次全网促销活动，涵盖了一些商品从上新时无人问津、到逐渐成为高潜力爆款的历程。欲获胜的队伍需格外关注曝光不足的商品上的推荐准确度，需探索“如何抵消掉历史点击数据的选择性偏差以便避免只推爆款”、“如何注意数据分布随时间的变化以便及时发现高潜力冷门好货”、“如何利用多模态图文商品信息来辅助商品冷启动”等重要课题。"
### 对抗推荐系统中经常遇到的马太效应
挖掘长尾商品（item-CF）？
### 获奖的解决方案需要在历史上很少接触的产品上表现良好。
不平衡学习思路： 数据工程，模型，优化：focus loss，AUC？
### 减少偏差
减少bias思路： 数据扩充，模型(集成学习) GBDT+LR？ 
### 培训数据和测试数据是在多个时期内收集的，趋势变化，对于可靠的预测不可避免地要执行偏差减小。
数据分布不规律？ 
### （匿名的）关键用户功能，数据偏差有弹性
数据缺失？ 树模型？


## 公平的理解
### 分类公平
我觉得应该是 保证不平衡分类，如使用AUC评价

### 排名公平
+ 排名中的统计均等性的简单解释是，确保出现在排名前缀中的受保护个体的比例高于给定比例
+ 需要确保在每个排名前缀处均出现最少数量的受保护成员
+ 2017_CIKM FAIR-一种公平的Top-k排名算法中提出了一种以最小的效用损失来确保公平的简单方法。个人的效用由低到高，而排名列表则以递增的方式建立。在每个位置，都会插入效用最高的个人，而不会违反公平性约束。

### 主题公平
+ 公平是在理想状态下实现的，在该理想状态下，受保护组与未受保护组相比会产生等级预测错误。通过四个不同的指标来量化与理想状态的偏差，这些指标在学习过程中作为正则化项引入。Beyond Parity: Fairness Objectives for Collaborative Filtering

### 对象公平
+ 承认输入数据中可能存在固有的偏差，因此推荐程序在不放大现有偏差的情况下（即避免偏差差异）被认为是公平的。具体而言：如，如果用户喜欢7部浪漫电影和3部动作电影，则推荐列表如果包含70％浪漫电影和30％动作电影，则是合理的。通过距离度量（KL散度）来量化与该状态的偏差。为了确保提出合理的建议，本着MMR的精神，采用了贪婪的迭代重新排序方法（后处理）。目的是构建一个列表，以平衡所选对象的效用和列表与输入首选项的偏差。
+ 

## NGCG的理解 
两个最受欢迎的排名指标是MAP和NDCG。我们在前段时间已经使用了平均精度均值（MAP）。NDCG表示归一化折损累积增益。两者之间的主要区别是，MAP认为是二元相关性（一个项是感兴趣的或者不感兴趣的），而NDCG允许以实数形式进行相关性打分。这种关系类似分类和回归的关系。

## 我们需要做什么？ 

+ 题中给出 train 下和 test下的  (usr_id; item_id; click_time) 
+ 我们需要给出  test_qtime下 (usr_id,click_time)  -->  预测的 item_id_list
+ item_id_list.length = 50 


## 怎么做？
### 1.选择框架？ panda ？ sklearn ？ tf ？ pytorch？


### 2.关于数据？ 
+ test中对某user来说test_qtime的时间是test_click最后一次点击的下一次点击

#### 如何处理时间和地点 以及 用户的点击行为？ 
#### test_qtime 下的时间信息如何理解？ 
#### 训练，测试，数据集如何构造 ？
#### 对缺失值的理解 ？ 
+ 用户缺失
+ 商品属性缺失

#### XHQ关于数据的理解 
+ 我们只有user点击过的item这一个数据，没有用户对item的评分。
+ 可以构造：user descriptor（不是所有用户都有？）、item descriptor
+ user的特征太少，参考价值可能不大（还是推荐系统都这样？或者考虑特征的权重）

### 3.模型如何选择？ 
+ 根据数据集特性来选择，目前数据 离散，且有多个缺失值

### 4.如何挖掘长尾商品（曝光度低的商品）？

#### LW关于挖掘长尾商品
+ 可以使用 item-CF，item-CF天生属性适合探测长尾
+ 转换为 不平衡学习： 数据，模型， 优化，评测 四方面 
+ 题目希望我们减少模型的偏差，集成学习？ boosting 搞起来？ 
+ 
#### XHQ关于赛题理解
+ 定义“historically rarely exposed”：某个item很少/从没有被某个用户点击过，那么对这个用户而言，这个item就是historically rarely exposed？

### 5.建模思路
#### 关联商品打分
+ 时间相隔越远的关联性肯定是不高？ 
+ 用户的有向性打分(连续点击item)*位置打分*时间打分，得到最终关联打分 ？ 

#### 交互行为打分
距离下次点击越近的行为，相关性越接大，所有可以根据位置远近考虑重要性，添加权重因子。当然还可以添加时间权重因子。

#### 正负样本怎么来？ 
需要我们去构造label。这里分为两步：

样本提取。我们线下验证的时候，一般是用户最后一次点击进行验证，会进行召回50个商品，然后观察召回率。这样的50个商品及对应的用户就是样本数据。
样本打标。召回的50个商品中是最后一次点击的商品labael是1，反之为0。

这样我们就能得到训练集，测试集构造方式一样，只不过需要去预测其label，最后将label的概率进行排序，top50就是最终建模得到的结果。

### 6.怎么召回 ？ 怎么标记？ 标记了怎么存？ 存了怎么读？ 


##  Mar-4
数据： 
+ 原始用户 len(user_feat) = 6789, 其中存在信息缺失，
+ 原始商品 len(item_feat） = 108915 ，且没有特征缺失
+ len(train_click_0_df) = 241784, 和原始用户重叠 3820 个 ， 只出现一次的用户有 16842个， 只出现一次的商品有 40772,  出现新商品 29466个(没有特征)， 出现新用户 13200(没有特征), 
+ 我们要返回的是 test_click-T中 user点击了一系列 item(或点击一次)后， test_qtime 下 反馈给 user 的item列表, test_click-T 是在 test_qtime之前的 。

如何构造训练集： 构造负样本
+  用户点击过 item ： 为 +1： 即出现在train_click中
+ 对所有的item的特征向量取平均向量avg_item_vector，user+avg_item_vector 作为负样本
+ 对于一个用户，用他所有没有过行为的数据作为负样本  bad 
+ 对于一个用户，从他没有过行为的负样本中均匀采样出一些作为负样本 not bad 
+ 对于一个用户，从他没有过行为的负样本中均匀采样出一些作为负样本， 且保证正负样本比为1：1, good 
+ 对于一个用户，从他没有过行为的负样本中均匀采样出一些作为负样本，但采样时，偏重采样那些热门却没有点击的样本。   同时保证 正负样本比例 1：1， very good
+ 一个客户浏览记录（item1-item2-item3-item4-item5）作为一个完整句子（word1-word2-word3-word4-word5）。word2vec中，比如CBoW，给定word1, word2, word4, word5,那么word3即为正样本。通过negative samping方法，采样的其他词语作为负样本。 对比到item的例子中，我理解在item1，item2， item4，item5作为context下，item3即为正样本，然后类似的，negative sampling方式按照item频率分布，采样出的其他item即为负样本。


X = [0/1,user_id/Feature,item_id/Feature,time,weight,count]
weight： 该item越热门权重越低 

+ user_id 和 item_id 可以理解为 类别特征，可用one—hot 编码或者 特征哈希的方法 
+ user 和 item 有一个相似矩阵：这个矩阵可以引入时间，可以将 user点击过的商品 列表作为 embdding向量。
+ 可以在训练阶段再引入 user 和item 的详细 Feature 

思路： 
分为召回和 排序两个阶段， 
+ 召回(有很多召回算法引入时间戳):
  + itemCF + time + UserCF  ,假设对 测试阶段的 每一个用户 召回 5000个item
  + 使用 MF 分解，召回得到 user 和 item 的隐向量 ， 隐向量可以和DNN 无缝对接，直接训练, 但是如何把 时间变量 引入 MF
+ 排序： 用 model(DeepFM,LR...) 对 5000个item 排序， 
  + y = model(user_id(Feature),item_id_(Feature),time_stap,context)  y 属于 [0,1] 
  + 如果召回物品列表 存在大量 新商品，可以 只对 存在的原始用户 or 原始商品 排序， 其余商品位置保持不变
  + 如果 测试集中存在大量新用户，构造 用户相似矩阵 M， 在M中找和 新用户最相似的用户 User_S，转而预测 User_S 

+ y = model(user_id(Feature),item_id_(Feature),time_stap,context)  y 属于 [0,1] 
+ 因为新用户和新商品并不是某一维特征 缺失，而是所有特征都没有，所以在 精排阶段，模型只能处理 原始商品或者 原始用户
+ 由于在训练集中 充斥着大量 新商品和新用户， 所以model，必须考虑 特征值填充，user/item 替换  
+ 


模型查找： 
DeepFM: (https://github.com/DariaYakovleva/deepFM-example/blob/master/deepFM.ipynb)

构造数据集： (https://github.com/SSSxCCC/Recommender-System/tree/master/Recommender_System/data)

DeepCTR-Torch(https://github.com/shenweichen/DeepCTR-Torch)

ctr_model_zoo(https://github.com/qian135/ctr_model_zoo) 带ipyth